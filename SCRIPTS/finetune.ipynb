{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying by skin cancer/disease type\n",
    "Six classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets (split into train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 27)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['img_id', 'diagnostic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surfd\\AppData\\Local\\Temp\\ipykernel_24180\\421877499.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['img_id'] = \"../DATA/images/\" + new_df['img_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# edit file path name\n",
    "new_df['img_id'] = \"../DATA/images/\" + new_df['img_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surfd\\AppData\\Local\\Temp\\ipykernel_24180\\4075627458.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['class'] = new_df['diagnostic'].map(mapping)\n"
     ]
    }
   ],
   "source": [
    "# edit skin disease names into numeric classes\n",
    "mapping = {'BCC':0, 'MEL':1, 'SCC':2 , 'ACK':3, 'NEV':4, 'SEK':5}\n",
    "new_df['class'] = new_df['diagnostic'].map(mapping)\n",
    "new_df = new_df.drop(['diagnostic'], axis=1)\n",
    "#new_df = new_df[['img_id', 'class', 'diagnostic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training (60%), testing (20%), and validation data (20%)\n",
    "train_df, temp = train_test_split(new_df, test_size=0.4, random_state=42)  # 60% train\n",
    "test_df, val_df = train_test_split(temp, test_size=0.5, random_state=42)  # Split remaining 40% equally\n",
    "\n",
    "train_df.to_csv(\"../data/train6.csv\", index=False)\n",
    "test_df.to_csv(\"../data/test6.csv\", index=False)\n",
    "val_df.to_csv(\"../data/val6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up to use Efficient Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup custom dataset\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.data.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment data / resize\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with dataloader\n",
    "\n",
    "train_dataset = SkinCancerDataset(csv_file='../data/train6.csv', transform=train_transforms)\n",
    "val_dataset = SkinCancerDataset(csv_file='../data/val6.csv', transform=val_transforms)\n",
    "test_dataset = SkinCancerDataset(csv_file='../data/test6.csv', transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\surfd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\surfd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# load EfficientNet and modify the classifier layer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_classes = len(train_dataset.data['class'].unique())\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dloader, ft_check):\n",
    "    model.eval()\n",
    "    dpreds, dlabels = [], []\n",
    "    dprobs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get the predicted class for each image (for accuracy and f1)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            # Get predicted probabilities for AUC (softmax output)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            dpreds.extend(preds.cpu().numpy())\n",
    "            dlabels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Store probabilities (for AUC)\n",
    "            dprobs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # for idx in dpreds:\n",
    "    #     label = list(mapping.keys())[list(mapping.values()).index(idx)]\n",
    "    #     prob = torch.softmax(outputs, dim=1)[0, idx].item()\n",
    "    #     print('{:<75} ({:.2f}%)'.format(label, prob*100))\n",
    "\n",
    "    accuracy = accuracy_score(dlabels, dpreds)\n",
    "    f1 = f1_score(dlabels, dpreds, average='macro')\n",
    "    auc = roc_auc_score(dlabels, dprobs, average='macro', multi_class='ovr')  # need to use probabilities instead of predictions for multiclass auc\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'AUC: {auc}')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(dlabels, dpreds)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=mapping.keys(), yticklabels=mapping.keys())\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "    # Using this code for evaluating both the base / pretrained model and the fine-tuned model\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    if(ft_check):\n",
    "        plt.title(\"Fine-tuned Efficient Net Model Confusion Matrix\")\n",
    "    else:\n",
    "        plt.title(\"Pre-trained Efficient Net Model Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_loader, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze earlier layers / only fine tune the bottom layer\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, '\n",
    "              f'Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "evaluate_model(model, test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'efficientnet_skin_cancer_classifier6.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying between Malignant and Benign\n",
    "Binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surfd\\AppData\\Local\\Temp\\ipykernel_24180\\786655237.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['img_id'] = \"../DATA/images/\" + new_df['img_id'].astype(str)\n",
      "C:\\Users\\surfd\\AppData\\Local\\Temp\\ipykernel_24180\\786655237.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['class'] = new_df['diagnostic'].map(mapping)\n",
      "c:\\Users\\surfd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\surfd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/metadata.csv\")\n",
    "new_df = df[['img_id', 'diagnostic']]\n",
    "new_df['img_id'] = \"../DATA/images/\" + new_df['img_id'].astype(str)\n",
    "\n",
    "# malignant - 1, benign - 0 (two classes)\n",
    "mapping = {'BCC':1, 'MEL':1, 'SCC':1 , 'ACK':0, 'NEV':0, 'SEK':0}\n",
    "new_df['class'] = new_df['diagnostic'].map(mapping)\n",
    "new_df = new_df.drop(['diagnostic'], axis=1)\n",
    "\n",
    "train_df, temp = train_test_split(new_df, test_size=0.4, random_state=42)  # 60% train\n",
    "test_df, val_df = train_test_split(temp, test_size=0.5, random_state=42)  # Split remaining 40% equally\n",
    "\n",
    "train_df.to_csv(\"../data/train2.csv\", index=False)\n",
    "test_df.to_csv(\"../data/test2.csv\", index=False)\n",
    "val_df.to_csv(\"../data/val2.csv\", index=False)\n",
    "\n",
    "# load data with dataloader\n",
    "train_dataset = SkinCancerDataset(csv_file='../data/train2.csv', transform=train_transforms)\n",
    "val_dataset = SkinCancerDataset(csv_file='../data/val2.csv', transform=val_transforms)\n",
    "test_dataset = SkinCancerDataset(csv_file='../data/test2.csv', transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# load EfficientNet and modify the classifier layer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_classes = len(train_dataset.data['class'].unique())\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_twoclass(model, dloader, ft_check):\n",
    "    model.eval()\n",
    "    dpreds, dlabels, dprobs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get the predicted class for each image (for accuracy and F1)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            # Get predicted probabilities for AUC (softmax output)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            dpreds.extend(preds.cpu().numpy())\n",
    "            dlabels.extend(labels.cpu().numpy())\n",
    "            dprobs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # # Print predictions with their probabilities\n",
    "    # for idx in dpreds:\n",
    "    #     label = \"Benign\" if dpreds == 0 else \"Malignant\"\n",
    "    #     prob = torch.softmax(outputs, dim=1)[0, idx].item()\n",
    "    #     print('{:<75} ({:.2f}%)'.format(label, prob*100))\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(dlabels, dpreds)\n",
    "    f1 = f1_score(dlabels, dpreds, average='macro')\n",
    "    auc = roc_auc_score(dlabels, dprobs, average='macro', multi_class='ovr')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'AUC: {auc}')\n",
    "\n",
    "    # Step 6: Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(dlabels, dpreds)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Benign\", \"Malignant\"], yticklabels=[\"Benign\", \"Malignant\"])\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    if(ft_check):\n",
    "        plt.title(\"Fine-tuned Efficient Net Model Confusion Matrix\")\n",
    "    else:\n",
    "        plt.title(\"Pre-trained Efficient Net Model Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test base model\n",
    "evaluate_model_twoclass(model, val_loader, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze earlier layers / only fine tune the bottom layer\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "evaluate_model_twoclass(model, test_loader, True)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), 'efficientnet_skin_cancer_classifier2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
